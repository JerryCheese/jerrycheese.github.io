<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[提高你的记忆力：记忆宫殿法]]></title>
    <url>%2F%2Fp%2F61075.html</url>
    <content type="text"><![CDATA[原文：知乎 - 世界上真的存在记忆宫殿吗？常人能掌握吗？ 世界上确实是存在记忆宫殿的，而且并不是一些人想象中那样玄妙和难以掌握，许多答主分享了自己建立记忆宫殿的经验和心得，就在这里给大家整理一下建立记忆宫殿的简单步骤吧。 建造记忆宫殿的原理我们的大脑擅长记忆图像信息与空间信息，而不擅长于记忆文字类信息（比如单词）。于是，人们试着将自己不擅长记忆的文字信息，转变为图像和空间信息来进行记忆，比如为自己造一座“记忆宫殿（memory palace）”。“记忆宫殿”被证明能有效地提升人们对文字的记忆力（Foer, 2011）。 建造属于自己的记忆宫殿只需要五步第一步：寻找一个合适的宫殿建议选择一个你熟悉的地方作为你的记忆宫殿，比如你的家，或是你平时习惯行走的街道。越是熟悉的场景，我们越是能在脑海中清晰地再现场景中的细节（比如摆设和建筑），也有利于我们接下来将需要记忆的内容与这些细节联系起来。 第二步：规划你在宫殿中行走的路线想象你走过平时上班会路过的街道，你会从哪里开始？你在哪里会拐弯？你选择在哪里结束？试着闭上眼、在脑海中多走几遍，直到我们确定这条路径已经牢牢映在我们的脑海中。要注意，每次走过的路线一定得是一样的。如果你选择把自己的家作为记忆宫殿，那么需要想清楚：一般从哪个房间开始？会经过哪些房间？在哪个房间停下，等等。 第三步：选择一些有特征的物品这一步要求你在宫殿中设置一些特征物。比如说街边的建筑、或是房间里的大型家具（床、柜子等）。建议选一些大的物体作为特征物，因为它们能更好地吸引我们的注意力。 现在，想象我们自己重新沿着第二步的路径行走，并在过程中注意那些特征物：你在街边看到的第一个建筑是什么？它是什么样的？第二个引起你注意的物体是什么？每条街上最好有5~10个不同的特征物。如果你觉得很难同时想象特征物与路径的话，你可以画下平面图，来帮助自己更好地进行空间想象。 第四步：把特征物和和记忆内容建立联系在这一步，把你想要记住的内容与你的记忆宫殿联系在一起。这些联系越是形象和荒诞，越是能加深我们的记忆。举个例子，比如你想记住一句英文，开头第一个单词是“mania（躁狂）”，它的第一个音节读起来很像“妈”，于是你可以在你的记忆宫殿的第一个特征物上印上一个“疯狂妈妈”的形象（比如，你走上街，发现自己看到的第一个建筑上印着一个大笑的、手舞足蹈的妈妈形象）。 接下来，按照顺序，用类似的方法将句子中剩下单词与宫殿中的特征物一一联系起来。这样，你就可以通过在宫殿中行走、浏览特征物，来复述句子了。 第五步：重复地参观你的宫殿这一步主要是巩固我们的记忆。在这一步中，我们从之前开始的地方、遵循先前的路线，重复地参观我们的宫殿。注意我们经过的特征物，当我们经过它们时，那些与特征物有关的记忆就会逐渐浮现。如果你觉得一开始有些困难，你还是可以用平面图、或者大声说出记忆内容的方法，来帮助你进行空间想象。而经过几次练习后，我们的空间想象能力会随之提高。 其他方法除了记忆宫殿之外，还有一些其他帮助记忆的技术可以帮助我们更长久、更准确的记忆。比如： 使用“闪存卡（flash card）”技术闪存卡技术是一项很有效的、帮助人们牢记知识点的方法（Boser, 2017)）。方法很简单，首先，将你需要记住的知识点，用提问和回答的方式，写在一张卡片的正反面（比如正面写“记忆的定义是？”，反面写上答案）；通过这样的方法，你可能会制作出一叠闪存卡。 随后，浏览这些卡片，将你能回答出的部分挑出放在一边，称为“已答卡”；而余下的卡片放在另一边，称为“未答卡”。接下来，反复地抽取和回答“未答卡”上的问题，直到你能将所有卡片上的问题都回答正确。你可以将一些闪存卡带在身边，在通勤时抽卡进行复习。 捏压力球研究发现，捏压力球有助于提升人的记忆能力。在一项实验中，右撇子参与者在开始记信息之前，用右手捏压力球45秒；在背完信息后，再用左手捏压力球45秒（左撇子参与者是先左手后右手）。结果显示，比起没有捏压力球的人，捏了压力球的参与者对信息记得更多、更牢。这可能是因为，用惯用手捏压力球，可以刺激大脑中负责解码、信息的区域，帮助我们更好地感知和分析需要记忆的信息（Szalavitz, 2013）。]]></content>
      <categories>
        <category>转载</category>
      </categories>
      <tags>
        <tag>知乎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Exercise2: Logistic Regression]]></title>
    <url>%2F%2Fp%2F48722.html</url>
    <content type="text"><![CDATA[序一个月快过去了，总算是学完Coursera上的第三课了，其实我的进度比预期满了一周。这是第二次做Coursera的编程作业，对比大学课程的作业，Coursera的难度应该在中等甚至偏下，对我来说唯一的难度在于适应“新”，有以下几点： 新语言 新工具 新的思考方式 对于一个Software Engineer来说以上都是最基础的技能，即保持学习态度，及时学习新技术、新知识。 第三周的课程内容主要讲分类、逻辑回归，与线性回归相比，也就是把Hypothesis函数用Sigmoid函数来表示，也就是：$设 g(z) = \frac{1} {1 + e ^{-z}}$，$令 z = θ^T x$，$则 h_θ(x) = g(θ^Tx)$ 为什么要 $设 g(z) = \frac{1} {1 + e ^{-z}}$ 呢，因为它的值域为 $(0, 1)$，定义域为(-∞, +∞) 的单调连续增函数，这意味着可以用换元法把所有函数的值域压缩到$(0, 1)$，它的函数图像如下。 这非常适合作为二分类（01分类）函数，我们可以取 $ hθ(x) &gt;= 0.5$ 时 $y = 1$ ，$ hθ(x) &lt; 0.5$ 时 $y = 0$ 。 同时Cost函数和Gradient Descent方程也有些许改变，这种改变是换元法带来的（公式识别失败，用图代替了） 它们对应的矩阵形式是 ① $J(θ) = \frac {1} {m} (- y ^T log(h) - (1 - y)^T log(1 - h))，h = g(Xθ)$ ② $θ = θ - \frac {α} {m} X^T (g(Xθ) - y)$ 注意其中$X、y、θ$ 都是矩阵 作业内容标*的是需要做的，没标的是作业中已经实现 数据可视化 * Sigdmoid函数12345678910111213141516function g = sigmoid(z)%SIGMOID Compute sigmoid function% g = SIGMOID(z) computes the sigmoid of z.% You need to return the following variables correctly g = zeros(size(z));% ====================== YOUR CODE HERE ======================% Instructions: Compute the sigmoid of each value of z (z can be a matrix,% vector or scalar). g = 1 ./ (1 + exp(-z));% =============================================================end 传入的参数是一个矩阵，所以需要算出每一个元素的sigmoid函数值，这里用到的./操作符来对每一个元素进行取倒数操作。 * Cost函数和对应的Gradient Descent方程123456789101112131415161718192021222324252627282930function [J, grad] = costFunction(theta, X, y)%COSTFUNCTION Compute cost and gradient for logistic regression% J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the% parameter for logistic regression and the gradient of the cost% w.r.t. to the parameters.% Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta.% You should set J to the cost.% Compute the partial derivatives and set grad to the partial% derivatives of the cost w.r.t. each parameter in theta%% Note: grad should have the same dimensions as theta%J = 1/m * sum(-y .* log(sigmoid(X * theta)) - (1 - y) .* log(1 - sigmoid(X * theta)));grad = 1/m * (X' * (sigmoid(X * theta) - y));% =============================================================end 在这个函数中需要同时计算代价和梯度，通过公式①、②不难得到上述两行代码 * Hypothesis函数1234567891011121314151617181920212223function p = predict(theta, X)%PREDICT Predict whether the label is 0 or 1 using learned logistic %regression parameters theta% p = PREDICT(theta, X) computes the predictions for X using a % threshold at 0.5 (i.e., if sigmoid(theta'*x) &gt;= 0.5, predict 1)m = size(X, 1); % Number of training examples% You need to return the following variables correctlyp = zeros(m, 1);% ====================== YOUR CODE HERE ======================% Instructions: Complete the following code to make predictions using% your learned logistic regression parameters. % You should set p to a vector of 0's and 1's%s = sigmoid(X * theta);p = floor(s + 0.5);% =========================================================================end 预测函数就比较简单的，由$则 h_θ(x) = g(θ^Tx)$，$g$ 是Sigmoid函数，可以得到上述两行代码，因为当函数值大于0.5时$y = 1$ ，又得到的 $s$ 其实是一个矩阵，所以使用floor(s + 0.5)来进行批量操作。 完成上述三个函数后，运行ex2函数可以得到一条预测线，如图。 * 正规化正规化是为了防止过拟合，核心是保持 $ x$ 值不变， 减小 (惩罚) $θ$的值。 当然还有一种方式防止过拟合的方法是建立一个模型来去除用处不大的特征，保留作用相对较大的特征。 上图表示的预测函数，从左到右依次是欠拟合、拟合 也叫刚好拟合、过拟合，欠拟合一般是因为多项式的最高次太小，过拟合一般是因为多项式的最高次幂太大。 正规化后的代价函数如下，注意尾巴上对 $θ_j$ 的求和是从1开始，也就意味着跳过了 $θ_0$ 值得注意的是梯度方程不需要对 $θ_0$ 进行正规化，所以方程变成了两部分： 12345678910111213141516171819202122232425262728function [J, grad] = costFunctionReg(theta, X, y, lambda)%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization% J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using% theta as the parameter for regularized logistic regression and the% gradient of the cost w.r.t. to the parameters. % Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta.% You should set J to the cost.% Compute the partial derivatives and set grad to the partial% derivatives of the cost w.r.t. each parameter in thetaJ = 1/m * sum(-y .* log(sigmoid(X * theta)) - (1 - y) .* log(1 - sigmoid(X * theta)));J = J + lambda/(2*m) * sum(theta(2:size(theta)) .^ 2);grad = 1/m * (X' * (sigmoid(X * theta) - y)) + lambda/m * theta;grad(1) = grad(1) - lambda/m * theta(1);% =============================================================end 根据上述的三张图不难写出上述四行代码 调整λ参数的大小λ = 1 λ = 10 λ = 0.0001 可以看出 $λ$ 越小，对训练样本的拟合程度越好，从而导致了整个曲线看起来比较扭曲，没有平滑感；而 $λ$ 越大，对训练样本的拟合程度越差，曲线越光滑。]]></content>
      <categories>
        <category>研</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7修改docker的Data Space Total大小]]></title>
    <url>%2F%2Fp%2F55543.html</url>
    <content type="text"><![CDATA[记得备份你的容器此处就不多做介绍了 –storage-opts 参数介绍devicemapper文档：https://github.com/moby/moby/tree/master/daemon/graphdriver/devmapperdocker官方文档：https://docs.docker.com/engine/reference/commandline/dockerd/#options-per-storage-driver 修改–storage-opts参数停止docker，修改配置，重新加载配置12sudo systemctl stop dockersudo vi /lib/systemd/system/docker.service 找到ExecStart=/usr/bin/dockerd在这一行后面加上--storage-opt dm.loopdatasize=8G --storage-opt dm.loopmetadatasize=4G --storage-opt dm.basesize=8G 意思是为，设置devicemapper的data为8G，metadata为4G，镜像的大小不能大于8G 记得还要抹去现有的空间，请确保你已经完成了第一步1234sudo rm -rf /var/lib/dockersudo mkdir -p /var/lib/docker/devicemapper/devicemapper/sudo dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/data bs=1M count=0 seek=8192sudo dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/metadata bs=1M count=0 seek=4096 完成后运行123sudo systemctl daemon-reloadsudo systemctl start dockerdocker info 查看是否设置正确，貌似比预设的大了一点点。]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>devopps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下使用命令行或脚本删除文件到废纸篓]]></title>
    <url>%2F%2Fp%2F35267.html</url>
    <content type="text"><![CDATA[mac删除文件有两种方式： 使用Finder的移到废纸篓功能 使用rm命令第二种方式删除的文件，不能在废纸篓中找到，也就是所谓的彻底删除但是我们在使用terminal的时候，一般都会使用rm删除文件，那要是删错了不就完了？而且我们的mac上本身又自带了废纸篓，为什么不能将两者结合起来呢？于是我做了一些探究 Mac废纸篓的真实面目1$ ls ~/.Trash 你会发现，~/.Trash目录就是废纸篓但是它只是一个普通的目录，只是Finder将删除的文件移动到了这个目录而已，不相信？接着往下看 ~/.Trash的本质只是文件夹123cd ~echo &quot;666666&quot; &gt;&gt; wantodel.txtmv wantodel.txt ~/.Trash 此时打开你的废纸篓一看，里面有一个wantodel.txt文件，但是你无法将它放回原处，而如果你使用Finder的移到废纸篓功能删除的文件却可以放回原处 Finder是如何实现放回原处的呢？最有可能是将操作记录到了数据库中。 不大可能写在log日志中，因为我grep了整个磁盘都没找到相关的文件。 最好的帮手是Finder既然~/.Trash只是普通文件夹，那我们单纯使用linux命令是无法达到目的的了。我们现在已知Finder可以达到预期目的，如果我们能调用或是告诉Finder的我们要做什么，并且它也愿意做，不就可以达到目的了么？在window中有一个消息的概念，意思是一个应用程序A可以对另一个应用程序B发送消息以操作B来完成某项指定的任务，那Mac种是否也有这种或是类似这种的机制呢？答案是AppleScript，是一种脚本语言，可以用来控制Mac上的应用程序。最后附上使用shell通知Finder程序移动文件废纸篓的样例代码1234567#!/bin/bashfp=/absolute/path/to/fileosascript &lt;&lt; EOFtell application "Finder" posix path of ((delete posix file "$&#123;fp&#125;") as unicode text)end tellEOF]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git托管现有代码]]></title>
    <url>%2F%2Fp%2F49319.html</url>
    <content type="text"><![CDATA[场景：将现有的文件托管至新的git repo 用到的命令： git clone 复制网络仓库到本地 git add [file] 加入一个文件/目录到版本控制 git commit 提交修改到仓库(本地) git push 推送对仓库的修改到网络仓库 操作步骤如果对一个非空目录执行clone命令是会失败的，因为git不允许这样做。 进入项目目录（非空），运行下面命令： 1234567cd /path/to/dirgit clone &#123;repo_url&#125; tmpmv tmp/.git .rmdir tmpgit add .git commit -m &apos;current files&apos;git push 解释.git是一个隐藏的git用于管理本地代码的目录 git clone {repo_url} tmp 其实是把远程repo加载到tmp目录 将tmp/.git 直接移动到项目的根目录后运行git add . 其实相当于是把项目的文件放到了本地的git repo中 此时运行git commit 就提交了现有项目文件到本地，git push 就把操作推向了服务器 操作完成后，你的另外一个同事就可以使用git clone {repo_url} 来加载你的代码]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>无标签</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打开FTP服务器上的文件夹时发生错误,请检查是否有权限访问该文件夹]]></title>
    <url>%2F%2Fp%2F11354.html</url>
    <content type="text"><![CDATA[环境：Wndows2012 R2， 已完成操作：FTP服务器搭建、防火墙规则允许(或关闭防火墙)、权限已给(Administrator) 客户端：FileZilla（或ie浏览器、windows资源管理器） 场景： 使用windows资源管理器连接ftp报错：“打开FTP服务器上的文件夹时发生错误,请检查是否有权限访问该文件夹” 使用FileZilla链接时超时 最后解决方法： 在FileZilla中将FTP模式改为PORT(主动模式)即可]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>无标签</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负数的除2和右移1位]]></title>
    <url>%2F%2Fp%2F14496.html</url>
    <content type="text"><![CDATA[令人费解的输出且看如下代码，试问输出是什么。 1234int F, G, X = -5;F = X / 2;G = X &gt;&gt; 1;Console.WriteLine(&quot;F = &#123;0&#125;, G= &#123;1&#125;&quot;, F, G); 老师说过“乘2是二进制左移1位”，那除2理所当然应该是右移1位，所以两者结果是一样的。 然而，输出却是F = -2, G = -3 ，在VS2013中，换成在codeblocks中，结果是一样的。 反汇编在VS2013中对上述代码反汇编得到下图 第一句：F = X / 2 1234500DF39F7 mov eax,dword ptr [ebp-58h] ;将X的值移到寄存器eax 00DF39FA mov ecx,2 ;将值2移到ecx 00DF39FF cdq ;将eax高位扩展到edx 00DF3A00 idiv eax,ecx ;做除法运算 00DF3A02 mov dword ptr [ebp-50h],eax ;移动到内存 idiv指令是带符号的二进制除法 第二句：G = X &gt;&gt; 1 逻辑右移，最低位被舍弃 结论除法运算，结果都向0取整；位运算结果向下取整]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编实现回文判断]]></title>
    <url>%2F%2Fp%2F9879.html</url>
    <content type="text"><![CDATA[不多说，直接上代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061DATA SEGMENT Prompt DB &apos;Please enter a string:$&apos; YesStr DB 13, 10, &apos;This string is palindrome$&apos; NoStr DB 13, 10, &apos;This string is not palindrome$&apos; Input DB 128, ?, 128 DUP(0) DATA ENDS STACK SEGMENT DB 128 DUP(?) STACK ENDS CODE SEGMENT ASSUME CS:CODE, DS:DATA, SS:STACK MAIN: MOV AX, DATA MOV DS, AX MOV DX, offset Prompt MOV AH, 09H INT 21H ; MOV DX, OFFSET Input MOV AH, 0AH INT 21H ; MOV DI, OFFSET Input MOV SI, OFFSET Input XOR CX, CX MOV CL, [DI+1] ADD DI, 2 ADD SI, 2 DEC CX ADD DI, CX ;force DI point to the last word of Input AGAIN: CMP SI, DI JA TESSKIP MOV AH, byte ptr [SI] MOV AL, byte ptr [DI] CMP AH, AL JNE NOSKIP INC SI DEC DI JMP AGAIN TESSKIP: MOV DX, OFFSET YesStr MOV AH, 09H INT 21H JMP ENDSKPI ; NOSKIP: MOV DX, OFFSET NoStr MOV AH, 09H INT 21H ; ENDSKPI: MOV AH, 4CH INT 21H CODE ENDS END MAIN]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
</search>
