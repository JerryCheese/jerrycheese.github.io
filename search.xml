<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Exercise2: Logistic Regression]]></title>
    <url>%2F2017%2F11%2FExercise2-Logistic-Regression.html</url>
    <content type="text"><![CDATA[序一个月快过去了，总算是学完Coursera上的第三课了，其实我的进度比预期满了一周。这是第二次做Coursera的编程作业，对比大学课程的作业，Coursera的难度应该在中等甚至偏下，对我来说唯一的难度在于适应“新”，有以下几点： 新语言 新工具 新的思考方式 对于一个Software Engineer来说以上都是最基础的技能，即保持学习态度，及时学习新技术、新知识。 第三周的课程内容主要讲分类、逻辑回归，与线性回归相比，也就是把Hypothesis函数用Sigmoid函数来表示，也就是：$设 g(z) = \frac{1} {1 + e ^{-z}}$，$令 z = θ^T x$，$则 h_θ(x) = g(θ^Tx)$ 为什么要 $设 g(z) = \frac{1} {1 + e ^{-z}}$ 呢，因为它的值域为 $(0, 1)$，定义域为(-∞, +∞) 的单调连续增函数，这意味着可以用换元法把所有函数的值域压缩到$(0, 1)$，它的函数图像如下。 这非常适合作为二分类（01分类）函数，我们可以取 $ hθ(x) &gt;= 0.5$ 时 $y = 1$ ，$ hθ(x) &lt; 0.5$ 时 $y = 0$ 。 同时Cost函数和Gradient Descent方程也有些许改变，这种改变是换元法带来的（公式识别失败，用图代替了） 它们对应的矩阵形式是 ① $J(θ) = \frac {1} {m} (- y ^T log(h) - (1 - y)^T log(1 - h))，h = g(Xθ)$ ② $θ = θ - \frac {α} {m} X^T (g(Xθ) - y)$ 注意其中$X、y、θ$ 都是矩阵 作业内容标*的是需要做的，没标的是作业中已经实现 数据可视化 * Sigdmoid函数12345678910111213141516function g = sigmoid(z)%SIGMOID Compute sigmoid function% g = SIGMOID(z) computes the sigmoid of z.% You need to return the following variables correctly g = zeros(size(z));% ====================== YOUR CODE HERE ======================% Instructions: Compute the sigmoid of each value of z (z can be a matrix,% vector or scalar). g = 1 ./ (1 + exp(-z));% =============================================================end 传入的参数是一个矩阵，所以需要算出每一个元素的sigmoid函数值，这里用到的./操作符来对每一个元素进行取倒数操作。 * Cost函数和对应的Gradient Descent方程123456789101112131415161718192021222324252627282930function [J, grad] = costFunction(theta, X, y)%COSTFUNCTION Compute cost and gradient for logistic regression% J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the% parameter for logistic regression and the gradient of the cost% w.r.t. to the parameters.% Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta.% You should set J to the cost.% Compute the partial derivatives and set grad to the partial% derivatives of the cost w.r.t. each parameter in theta%% Note: grad should have the same dimensions as theta%J = 1/m * sum(-y .* log(sigmoid(X * theta)) - (1 - y) .* log(1 - sigmoid(X * theta)));grad = 1/m * (X' * (sigmoid(X * theta) - y));% =============================================================end 在这个函数中需要同时计算代价和梯度，通过公式①、②不难得到上述两行代码 * Hypothesis函数1234567891011121314151617181920212223function p = predict(theta, X)%PREDICT Predict whether the label is 0 or 1 using learned logistic %regression parameters theta% p = PREDICT(theta, X) computes the predictions for X using a % threshold at 0.5 (i.e., if sigmoid(theta'*x) &gt;= 0.5, predict 1)m = size(X, 1); % Number of training examples% You need to return the following variables correctlyp = zeros(m, 1);% ====================== YOUR CODE HERE ======================% Instructions: Complete the following code to make predictions using% your learned logistic regression parameters. % You should set p to a vector of 0's and 1's%s = sigmoid(X * theta);p = floor(s + 0.5);% =========================================================================end 预测函数就比较简单的，由$则 h_θ(x) = g(θ^Tx)$，$g$ 是Sigmoid函数，可以得到上述两行代码，因为当函数值大于0.5时$y = 1$ ，又得到的 $s$ 其实是一个矩阵，所以使用floor(s + 0.5)来进行批量操作。 完成上述三个函数后，运行ex2函数可以得到一条预测线，如图。 * 正规化正规化是为了防止过拟合，核心是保持 $ x$ 值不变， 减小 (惩罚) $θ$的值。 当然还有一种方式防止过拟合的方法是建立一个模型来去除用处不大的特征，保留作用相对较大的特征。 上图表示的预测函数，从左到右依次是欠拟合、拟合 也叫刚好拟合、过拟合，欠拟合一般是因为多项式的最高次太小，过拟合一般是因为多项式的最高次幂太大。 正规化后的代价函数如下，注意尾巴上对 $θ_j$ 的求和是从1开始，也就意味着跳过了 $θ_0$ 值得注意的是梯度方程不需要对 $θ_0$ 进行正规化，所以方程变成了两部分： 12345678910111213141516171819202122232425262728function [J, grad] = costFunctionReg(theta, X, y, lambda)%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization% J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using% theta as the parameter for regularized logistic regression and the% gradient of the cost w.r.t. to the parameters. % Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta.% You should set J to the cost.% Compute the partial derivatives and set grad to the partial% derivatives of the cost w.r.t. each parameter in thetaJ = 1/m * sum(-y .* log(sigmoid(X * theta)) - (1 - y) .* log(1 - sigmoid(X * theta)));J = J + lambda/(2*m) * sum(theta(2:size(theta)) .^ 2);grad = 1/m * (X&apos; * (sigmoid(X * theta) - y)) + lambda/m * theta;grad(1) = grad(1) - lambda/m * theta(1);% =============================================================end 根据上述的三张图不难写出上述四行代码 调整λ参数的大小λ = 1 λ = 10 λ = 0.0001 可以看出 $λ$ 越小，对训练样本的拟合程度越好，从而导致了整个曲线看起来比较扭曲，没有平滑感；而 $λ$ 越大，对训练样本的拟合程度越差，曲线越光滑。]]></content>
      <categories>
        <category>研</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7修改docker的Data Space Total大小]]></title>
    <url>%2F2017%2F11%2FCentos7%E4%BF%AE%E6%94%B9docker%E7%9A%84Data-Space-Total%E5%A4%A7%E5%B0%8F.html</url>
    <content type="text"><![CDATA[记得备份你的容器此处就不多做介绍了 –storage-opts 参数介绍devicemapper文档：https://github.com/moby/moby/tree/master/daemon/graphdriver/devmapperdocker官方文档：https://docs.docker.com/engine/reference/commandline/dockerd/#options-per-storage-driver 修改–storage-opts参数停止docker，修改配置，重新加载配置12sudo systemctl stop dockersudo vi /lib/systemd/system/docker.service 找到ExecStart=/usr/bin/dockerd在这一行后面加上--storage-opt dm.loopdatasize=8G --storage-opt dm.loopmetadatasize=4G --storage-opt dm.basesize=8G 意思是为，设置devicemapper的data为8G，metadata为4G，镜像的大小不能大于8G 记得还要抹去现有的空间，请确保你已经完成了第一步1234sudo rm -rf /var/lib/dockersudo mkdir -p /var/lib/docker/devicemapper/devicemapper/sudo dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/data bs=1M count=0 seek=8192sudo dd if=/dev/zero of=/var/lib/docker/devicemapper/devicemapper/metadata bs=1M count=0 seek=4096 完成后运行123sudo systemctl daemon-reloadsudo systemctl start dockerdocker info 查看是否设置正确，貌似比预设的大了一点点。]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>devopps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下使用命令行或脚本删除文件到废纸篓]]></title>
    <url>%2F2017%2F10%2FMac%E4%B8%8B%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%88%96%E8%84%9A%E6%9C%AC%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%E5%88%B0%E5%BA%9F%E7%BA%B8%E7%AF%93.html</url>
    <content type="text"><![CDATA[mac删除文件有两种方式： 使用Finder的移到废纸篓功能 使用rm命令第二种方式删除的文件，不能在废纸篓中找到，也就是所谓的彻底删除但是我们在使用terminal的时候，一般都会使用rm删除文件，那要是删错了不就完了？而且我们的mac上本身又自带了废纸篓，为什么不能将两者结合起来呢？于是我做了一些探究 Mac废纸篓的真实面目1$ ls ~/.Trash 你会发现，~/.Trash目录就是废纸篓但是它只是一个普通的目录，只是Finder将删除的文件移动到了这个目录而已，不相信？接着往下看 ~/.Trash的本质只是文件夹123cd ~echo &quot;666666&quot; &gt;&gt; wantodel.txtmv wantodel.txt ~/.Trash 此时打开你的废纸篓一看，里面有一个wantodel.txt文件，但是你无法将它放回原处，而如果你使用Finder的移到废纸篓功能删除的文件却可以放回原处 Finder是如何实现放回原处的呢？最有可能是将操作记录到了数据库中。 不大可能写在log日志中，因为我grep了整个磁盘都没找到相关的文件。 最好的帮手是Finder既然~/.Trash只是普通文件夹，那我们单纯使用linux命令是无法达到目的的了。我们现在已知Finder可以达到预期目的，如果我们能调用或是告诉Finder的我们要做什么，并且它也愿意做，不就可以达到目的了么？在window中有一个消息的概念，意思是一个应用程序A可以对另一个应用程序B发送消息以操作B来完成某项指定的任务，那Mac种是否也有这种或是类似这种的机制呢？答案是AppleScript，是一种脚本语言，可以用来控制Mac上的应用程序。最后附上使用shell通知Finder程序移动文件废纸篓的样例代码1234567#!/bin/bashfp=/absolute/path/to/fileosascript &lt;&lt; EOFtell application "Finder" posix path of ((delete posix file "$&#123;fp&#125;") as unicode text)end tellEOF]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git托管现有代码]]></title>
    <url>%2F2017%2F02%2Fgit%E6%89%98%E7%AE%A1%E7%8E%B0%E6%9C%89%E4%BB%A3%E7%A0%81.html</url>
    <content type="text"><![CDATA[场景：将现有的文件托管至新的git repo 用到的命令： git clone 复制网络仓库到本地 git add [file] 加入一个文件/目录到版本控制 git commit 提交修改到仓库(本地) git push 推送对仓库的修改到网络仓库 操作步骤如果对一个非空目录执行clone命令是会失败的，因为git不允许这样做。 进入项目目录（非空），运行下面命令： 1234567cd /path/to/dirgit clone &#123;repo_url&#125; tmpmv tmp/.git .rmdir tmpgit add .git commit -m &apos;current files&apos;git push 解释.git是一个隐藏的git用于管理本地代码的目录 git clone {repo_url} tmp 其实是把远程repo加载到tmp目录 将tmp/.git 直接移动到项目的根目录后运行git add . 其实相当于是把项目的文件放到了本地的git repo中 此时运行git commit 就提交了现有项目文件到本地，git push 就把操作推向了服务器 操作完成后，你的另外一个同事就可以使用git clone {repo_url} 来加载你的代码]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>notag</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打开FTP服务器上的文件夹时发生错误,请检查是否有权限访问该文件夹]]></title>
    <url>%2F2017%2F01%2F%E6%89%93%E5%BC%80FTP%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9%E6%97%B6%E5%8F%91%E7%94%9F%E9%94%99%E8%AF%AF-%E8%AF%B7%E6%A3%80%E6%9F%A5%E6%98%AF%E5%90%A6%E6%9C%89%E6%9D%83%E9%99%90%E8%AE%BF%E9%97%AE%E8%AF%A5%E6%96%87%E4%BB%B6%E5%A4%B9.html</url>
    <content type="text"><![CDATA[环境：Wndows2012 R2， 已完成操作：FTP服务器搭建、防火墙规则允许(或关闭防火墙)、权限已给(Administrator) 客户端：FileZilla（或ie浏览器、windows资源管理器） 场景： 使用windows资源管理器连接ftp报错：“打开FTP服务器上的文件夹时发生错误,请检查是否有权限访问该文件夹” 使用FileZilla链接时超时 最后解决方法： 在FileZilla中将FTP模式改为PORT(主动模式)即可]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>notag</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[负数的除2和右移1位]]></title>
    <url>%2F2016%2F02%2F%E8%B4%9F%E6%95%B0%E7%9A%84%E9%99%A42%E5%92%8C%E5%8F%B3%E7%A7%BB1%E4%BD%8D.html</url>
    <content type="text"><![CDATA[令人费解的输出且看如下代码，试问输出是什么。 1234int F, G, X = -5;F = X / 2;G = X &gt;&gt; 1;Console.WriteLine(&quot;F = &#123;0&#125;, G= &#123;1&#125;&quot;, F, G); 老师说过“乘2是二进制左移1位”，那除2理所当然应该是右移1位，所以两者结果是一样的。 然而，输出却是F = -2, G = -3 ，在VS2013中，换成在codeblocks中，结果是一样的。 反汇编在VS2013中对上述代码反汇编得到下图 第一句：F = X / 2 1234500DF39F7 mov eax,dword ptr [ebp-58h] ;将X的值移到寄存器eax 00DF39FA mov ecx,2 ;将值2移到ecx 00DF39FF cdq ;将eax高位扩展到edx 00DF3A00 idiv eax,ecx ;做除法运算 00DF3A02 mov dword ptr [ebp-50h],eax ;移动到内存 idiv指令是带符号的二进制除法 第二句：G = X &gt;&gt; 1 逻辑右移，最低位被舍弃 结论除法运算，结果都向0取整；位运算结果向下取整]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编实现回文判断]]></title>
    <url>%2F2015%2F12%2F%E6%B1%87%E7%BC%96%E5%AE%9E%E7%8E%B0%E5%9B%9E%E6%96%87%E5%88%A4%E6%96%AD.html</url>
    <content type="text"><![CDATA[不多说，直接上代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061DATA SEGMENT Prompt DB &apos;Please enter a string:$&apos; YesStr DB 13, 10, &apos;This string is palindrome$&apos; NoStr DB 13, 10, &apos;This string is not palindrome$&apos; Input DB 128, ?, 128 DUP(0) DATA ENDS STACK SEGMENT DB 128 DUP(?) STACK ENDS CODE SEGMENT ASSUME CS:CODE, DS:DATA, SS:STACK MAIN: MOV AX, DATA MOV DS, AX MOV DX, offset Prompt MOV AH, 09H INT 21H ; MOV DX, OFFSET Input MOV AH, 0AH INT 21H ; MOV DI, OFFSET Input MOV SI, OFFSET Input XOR CX, CX MOV CL, [DI+1] ADD DI, 2 ADD SI, 2 DEC CX ADD DI, CX ;force DI point to the last word of Input AGAIN: CMP SI, DI JA TESSKIP MOV AH, byte ptr [SI] MOV AL, byte ptr [DI] CMP AH, AL JNE NOSKIP INC SI DEC DI JMP AGAIN TESSKIP: MOV DX, OFFSET YesStr MOV AH, 09H INT 21H JMP ENDSKPI ; NOSKIP: MOV DX, OFFSET NoStr MOV AH, 09H INT 21H ; ENDSKPI: MOV AH, 4CH INT 21H CODE ENDS END MAIN]]></content>
      <categories>
        <category>软件技术</category>
      </categories>
      <tags>
        <tag>汇编</tag>
      </tags>
  </entry>
</search>
